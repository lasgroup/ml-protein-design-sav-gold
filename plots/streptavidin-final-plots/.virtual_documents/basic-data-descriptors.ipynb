from mutedpy.experiments.streptavidin.streptavidin_loader import load_first_round




x,y,dts = load_first_round()
dts


mask5_site = dts['class']=='1st-5site'
mask2_site = dts['class']=='1st-2site'
print ("5-site")
print ("Total",len(dts[mask5_site]['variant']))
print ("Unique",len(dts[mask5_site]['variant'].unique()))


print ("All")
print ("Total",len(dts['variant']))
print ("Unique",len(dts['variant'].unique()))


from scipy.stats import shapiro
from mutedpy.protein_learning.regression.regression_ards import ARDModelLearner, ProteinKernelLearner
from stpy.helpers.helper import estimate_std
from mutedpy.utils.sequences.sequence_utils import from_integer_to_variants
import torch 
import matplotlib.pyplot as plt 
from matplotlib.gridspec import GridSpec
from scipy.stats import norm
import numpy as np 


residuals_mean_list, out, counts, residuals_mean, indices = estimate_std(x,y,verbose=True, return_all_residuals=True)
print ("Estimate of residuals")
s = estimate_std(x,y,verbose=True)


out, indices, counts = torch.unique(x, dim=0, return_inverse=True, return_counts=True)


print ("Data points from variants that appear at least once")
torch.sum(counts > 1)


s = estimate_std(x,y,verbose=True)
print ("Estimate of the std.", s)


# iterate over large counts and select means and values
on_x_axis = []
on_x_axis_mean = []
means = []
vals = []
stds = []
variants = from_integer_to_variants(out)
for i in range(counts.size()[0]):
    if counts[i] > 2:
        mask = indices == i
        for _ in range(counts[i]):
            on_x_axis.append(variants[i])
        on_x_axis_mean.append(variants[i])
        mean = torch.mean(y[mask].view(-1))
        means.append(mean)
        vals += y[mask].view(-1).tolist()
        stds.append(float(torch.std(y[mask].view(-1))))


print (stds)
ordering = np.argsort(np.array(stds))
on_x_axis_mean = np.array(on_x_axis_mean)[ordering]
means = np.array(means)[ordering]



fig = plt.figure(figsize=(10, 5),constrained_layout=True)
gs = GridSpec(nrows=1, ncols=3, wspace=0.3)

ax0 = fig.add_subplot(gs[0, 0:2])
ax0.errorbar(on_x_axis_mean,means,yerr =2*s, marker = 'D',color = "tab:orange",linestyle = "", ms = 5)
ax0.set_xticklabels(on_x_axis_mean)
ax0.set_xticklabels(on_x_axis_mean, rotation = 90)

ax0.plot(on_x_axis,vals,'ko', ms = 5)
#ax0.plot(on_x_axis_mean,np.array(stds)[ordering],'bo', ms = 5)



ax0.xaxis.grid(True)
#plt.grid("--", color = 'gray')
ax0.set_xlabel("Sav mutants with multiple data points")
ax0.set_ylabel("$\log_{10}$ Relative cell-specific activity")

ax1 = fig.add_subplot(gs[0, 2])
ax1.hist(residuals_mean, density = True, bins = 40, color = 'tab:blue')
x_axis = np.linspace(-1,1, 1000)
ax1.plot(x_axis, norm.pdf(x_axis, 0., s), color = 'tab:orange')
ax1.xaxis.grid(True)
ax1.yaxis.grid(True)
ax1.set_ylabel("Normalized occurence")
ax1.set_xlabel("$\log_{10}$ Relative cell-specific activity deviation")
plt.subplots_adjust(bottom=0.20, right = 1.05, left = 0.0)
plt.savefig("Noise-analysis.pdf", dpi = 200,bbox_inches='tight')


for i in range(counts.size()[0]):
    if counts[i] > 4:
        mask = indices == i
        print (shapiro(y[mask].view(-1)))


from mutedpy.experiments.streptavidin.streptavidin_loader import load_second_round
from mutedpy.experiments.streptavidin.streptavidin_loader import load_third_round, load_last_round


x2,y2,dts2 = load_second_round()
x3,y3,dts3 = load_third_round()
x4,y4,dts4 = load_last_round()





print ("Second round variants", len(dts2))
print (dts2['class'].value_counts())


print ("Third round variants", len(dts3))
print (dts3['class'].value_counts())


print ("Fourth round variants", len(dts4))
print (dts4['class'].value_counts())


# Noise analysis in the subseqeunt rounds


from mutedpy.experiments.streptavidin.active_learning.compare_different_models import load_model_and_mean_std, load_model



GP, embed, model_dict = load_model("/home/mojko/Documents/PhD_Projects/protein-design-pet/mutedpy/experiments/streptavidin/active_learning_3/AA_model/params/final_model_params_Jan_05.p","fit, before update",model_params_return=True)



import torch
torch.unique(torch.diag(GP.Sigma))



